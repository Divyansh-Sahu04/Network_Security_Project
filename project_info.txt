# Large data consists of 11k+ records
# connected to mongodb atlas
# networkdataextract-- etl pipeline
# push data-- etl pipeline
# we are writing all the config in entity folder
# our data should have same schema(same number of features)
# data drift report
# validate no of columns numerical column exist
 